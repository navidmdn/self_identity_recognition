{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from operator import add\n",
    "from collections import Counter\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex\n",
    "import json\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import countDistinct, col, udf, stddev, avg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRODIGY_DATASET_PATH = 'data/prodigy/descriptions.jsonl'\n",
    "TWITTER_PROFILE_PATHS = 'data/*_user_info.txt'\n",
    "IDENTITY_DICTIONARIES_PATH = 'data/identities/'\n",
    "PRODIGY_PATTERN_FILE_PATH = 'data/prodigy/patterns.jsonl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------+-----------+----+---------+------------+--------------------+---------------+-------------+--------------------+----------+---------+--------------+----+--------------------+------------------+-----------+-----------------------+--------+\n",
      "|               uid|            name|screen_name| url|protected|    location|         description|followers_count|friends_count|          created_at|utc_offset|time_zone|statuses_count|lang|   status_created_at|status_coordinates|status_lang|profile_image_url_https|verified|\n",
      "+------------------+----------------+-----------+----+---------+------------+--------------------+---------------+-------------+--------------------+----------+---------+--------------+----+--------------------+------------------+-----------+-----------------------+--------+\n",
      "|        2590887015|        Jennifer|    jp62783|None|    False|        null|                null|              5|           12|Sun Jun 08 01:41:...|      None|     None|             3|  en|Tue Nov 04 23:14:...|              null|         en|   https://pbs.twimg...|   False|\n",
      "|         264938313|Joris Pijnenborg|   Jorisp86|None|     True|        null|UvT | Internation...|            105|          124|Sat Mar 12 18:22:...|     -7200|Greenland|           390|  en|                null|              null|       null|   https://pbs.twimg...|   False|\n",
      "|757908114523893760|       แฟคเตอร์.|    GYU97MG|None|    False|❤=@pledis_17|SAY THE NAME!  SE...|              1|           17|Tue Jul 26 11:59:...|      None|     None|            96|  en|Sun Jun 18 13:23:...|              null|        und|   https://pbs.twimg...|   False|\n",
      "+------------------+----------------+-----------+----+---------+------------+--------------------+---------------+-------------+--------------------+----------+---------+--------------+----+--------------------+------------------+-----------+-----------------------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"uid\",StringType(),True),\n",
    "    StructField('name',StringType(),True),\n",
    "    StructField(\"screen_name\",StringType(),True),\n",
    "    StructField('url',StringType(),True),\n",
    "    StructField('protected',StringType(),True),\n",
    "    StructField('location',StringType(),True),\n",
    "    StructField('description',StringType(),True),\n",
    "    StructField(\"followers_count\",IntegerType(),True),\n",
    "    StructField(\"friends_count\",IntegerType(),True),\n",
    "    StructField(\"created_at\",StringType(),True),\n",
    "    StructField(\"utc_offset\",StringType(),True),\n",
    "    StructField('time_zone',StringType(),True),\n",
    "    StructField(\"statuses_count\",IntegerType(),True),\n",
    "    StructField(\"lang\",StringType(),True),\n",
    "    StructField(\"status_created_at\",StringType(),True),\n",
    "    StructField('status_coordinates',StringType(),True),\n",
    "    StructField(\"status_lang\",StringType(),True),\n",
    "    StructField(\"profile_image_url_https\",StringType(),True),\n",
    "    StructField(\"verified\",StringType(),True)\n",
    "])\n",
    "\n",
    "spark = SparkSession.builder.appName(\"spark-app\").config(\"PYSPARK_PYTHON\",\"python\").getOrCreate()\n",
    "profiles = spark.read.csv(TWITTER_PROFILE_PATHS, header=False, sep=\"\\t\", schema=schema)\n",
    "\n",
    "profiles.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering english and regex matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial df size: 1394484\n",
      "after filtering english profiles: 408237\n"
     ]
    }
   ],
   "source": [
    "def regex_filters(df, regex_list):\n",
    "    for i, regex in enumerate(regex_list):\n",
    "        df = df.filter(profiles.description.rlike(regex))\n",
    "    return df\n",
    "\n",
    "print(\"initial df size:\", profiles.count())\n",
    "\n",
    "eng_filtered = profiles.filter(\n",
    "    (profiles.lang.startswith(\"en\")) &\n",
    "    (profiles.status_lang.startswith(\"en\"))\n",
    ")\n",
    "\n",
    "print(\"after filtering english profiles:\", eng_filtered.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237482"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_filtered.filter(profiles.description.isNotNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after applying regex size: 2554\n",
      "CPU times: user 11.9 ms, sys: 5.69 ms, total: 17.6 ms\n",
      "Wall time: 6.78 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(description='I am an Oakwood Man, author, actor, and producer. Follow me, as I follow Christ!'),\n",
       " Row(description='I am whole, I am fearfully and wonderfully made, humane, I am a mother/gmom, helper 2 mankind, singer, teacher, student, servant, leader...'),\n",
       " Row(description=\"I am aware, that I am an asshole. I really don't care, about all of that though.\"),\n",
       " Row(description=\"17. I Love bands. I Like to take photos of stuff. I'm a nerd. follow my tumblr  http://t.co/K2KehN3X\"),\n",
       " Row(description=\"I'm a Christian, working man, and dad\")]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "regex_list = [\n",
    "    \"((\\w\\s*)+[,|#/]\\s*)\",\n",
    "    \"(i am a )|(I am a )|(I'm a )|(i'm a )|(i am an )|(I am an )|(I'm an )|(i'm an )\",\n",
    "]\n",
    "\n",
    "regex_filtered = regex_filters(eng_filtered, regex_list)\n",
    "print(\"after applying regex size:\", regex_filtered.count())\n",
    "\n",
    "regex_filtered.select('description').head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving descriptions in prodigy format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "descs = list(map(\n",
    "    lambda x: x.description,\n",
    "    regex_filtered.select('description').collect()\n",
    "))\n",
    "\n",
    "with open(PRODIGY_DATASET_PATH, 'w') as f:\n",
    "    for desc in descs:\n",
    "        f.write(json.dumps({'text': desc}) + '\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting prodigy patterns from dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file: data/identities/job_identities.txt\n",
      "reading file: data/identities/national_identities.txt\n",
      "reading file: data/identities/uga_identities.txt\n",
      "reading file: data/identities/identities.txt\n",
      "reading file: data/identities/racial_slur_identities.txt\n",
      "reading file: data/identities/wordnet_identities.txt\n",
      "reading file: data/identities/twitter_identities.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ignored_ids = ['person', 'god', 'a', 'fan']\n",
    "\n",
    "def extract_prodigy_patterns(identities_dir):\n",
    "    \n",
    "    def build_pattern(words, label='IDENTITY'):\n",
    "        return {\n",
    "            'label': label,\n",
    "            'pattern': [{'lower': _id_part.lower()} for _id_part in words.split(' ')]\n",
    "        }\n",
    "            \n",
    "    patterns = []   \n",
    "    for id_rel_path in os.listdir(identities_dir):\n",
    "        \n",
    "        id_path = os.path.join(identities_dir, id_rel_path)\n",
    "        print('reading file:', id_path)\n",
    "        \n",
    "        with open(id_path, 'r') as f:\n",
    "            \n",
    "            ids = f.read().split('\\n')\n",
    "            for _id in ids:\n",
    "                \n",
    "                if len(_id) == 0 or _id in ignored_ids:\n",
    "                    continue\n",
    "                \n",
    "                pattern = build_pattern(_id)\n",
    "                patterns.append(json.dumps(pattern))\n",
    "    return patterns\n",
    "        \n",
    "patterns = extract_prodigy_patterns(IDENTITY_DICTIONARIES_PATH)\n",
    "\n",
    "with open(PRODIGY_PATTERN_FILE_PATH, 'w') as f:\n",
    "    f.write('\\n'.join(patterns))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
